%!TEX root = skripsi.tex
%-----------------------------------------------------------------------------%
\chapter{\babEmpat} \label{implementasi}
%-----------------------------------------------------------------------------%
Bab ini akan menjelaskan perihal implementasi dari rancangan yang sudah dibuat pada bab sebelumnya.

\section{Pre-Processing}
Perlu dilakukan \textit{pre-processing} untuk memisahkan kalimat bahasa Inggris dan bahasa Indonesia dari korpus identik menjadi dua buah \textit{file} paralel untuk dapat diproses pada tahap-tahap berikutnya.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/pre-process-giza}
	\caption{Pre-Processing Giza}
	\label{fig:Pre-Processing-Giza}
\end{figure}


\section{Pembuatan \textit{Sense Tagged Corpus} Bahasa Inggris}
\textit{Sense Tagged Corpus} dibuat dengan menggunakan bantuan IMS untuk memberikan tag pada korpus bahasa Inggris. \textit{Pre-processing} dilakukan terlebih dahulu terhadap korpus bahasa Inggris seperti menghilangkan tanda baca dan mengubah semua token menjadi huruf kecil. Proses \textit{tagging} dilakukan dengan menjalankan perintah:

\begin{lstlisting}[language=bash, caption={IMS}, label={IMS}]
./testPlain.bash <model> <file_input> <file_output> <file_index_sense>
\end{lstlisting}

model yang digunakan IMS pada penelitian ini adalah model yang tersedia pada \textit{website software NUS} berdasarkan versi Wordnet 3.0. Model yang digunakan tersebut meliputi hasil \textit{training} kata-kata dalam bahasa Inggris yang sudah dilakukan di penelitian IMS. Proses yang dilakukan IMS dalam melakukan \textit{tagging sense} adalah dengan mengiterasikan melakukan \textit{sentence splitter}, \textit{tokenizing}, \textit{POS Tagging}, dan \textit{lemmatizing}. Setelah proses itu dilakukan, ekstraksi fitur dilakukan sebelum hasilnya masuk ke dalam \textit{classifier} berdasarkan model kata yang sudah ada. 


Hasil \textit{output} dari \textit{tool} tersebut adalah korpus dengan kata-kata sudah ditag dengan maknanya yang bersesuaian (dalam bentuk \textit{sense key}). \textit{Sense key} merupakan \textit{identifier} unik yang menyimpan arti dari suatu kata pada Wordnet Princeton. Untuk mempermudah pemakaian \textit{sense tagged corpus} ini pada proses selanjutnya, dilakukan \textit{post-processing} untuk mengubah hasil keluaran ke dalam format berikut:

\begin{lstlisting}
<sentence>kata-1||sensekey-1 kata-2||sensekey-2 ...</sentence>
<sentence>kata-n||sensekey-n kata-m||sensekey-m ...</sentence>
...
\end{lstlisting}

Contoh dari kalimat yang sudah diberikan \textit{tag} sampai keluar dari \textit{post-processing} adalah:

\begin{lstlisting}
<sentence>years||year%1:28:01:: animals||animal%1:03:00:: have||have%2:40:04:: caused||cause%2:36:00:: havoc||havoc%1:04:00::</sentence>
\end{lstlisting}

Pada contoh tersebut, kata years memiliki \textit{sense key} berupa "year\%1:28:01::", dimana berdasarkan Wordnet mempunyai arti sebagai '\textit{a period of time containing 365 (or 366) days}'. Tidak semua kata dalam korpus bahasa Inggris ditag oleh IMS, kata-kata sapaan seperti "I", "you", "a" , "the", dan beberapa kata lainnya tidak diberikan \textit{sense key}.  



\section{\textit{Word Alignment}}

\subsection{Pemrosesan \textit{Word Alignment}}
Proses \textit{word alignment} menggunakan dua buah \textit{file} yaitu korpus berbahasa Indonesia dan Inggris yang sudah dipisah dari \textit{pre-processing}. Perintah berikut digunakan untuk melakukan \textit{word alignment} dengan Giza pada penelitian ini:

\begin{lstlisting}[language=bash,caption={Word Alignment}, label={word-alignment}]
# Lakukan pada direktori Giza
./plain2snt.out [source_language] [target_language]

# proses diatas menghasilkan tiga buah file yaitu dua buah file vocabulary yang berisi indeks dengan kata (bahasa asal, dan bahasa tujuan), dan satu buah file snt yang berisi \textit{alignment} dari kalimat.

./snt2cooc.out [source_language_vcb_file] [target_language_vcb_file] [snt_file] > [coocurrence_file]

# proses snt2cooc akan menghasilkan \textit{cooccurence file}

./GIZA++ -S [source_language_vcb] -T [target_language_vcb] -C [snt_file] -CoocurrenceFile [cooc_file]
\end{lstlisting}

Giza mengeluarkan beberapa \textit{file} hasil dari proses tersebut. \textit{Output} yang akan digunakan diantaranya adalah \textit{file} bernama A3.final yang merupakan pasangan kalimat dengan kata-kata yang sudah dipasangkan sesuai dengan prediksi terbaik hasil pemrosesan Giza.

\subsection{Post-Processing}
Setelah mendapatkan \textit{file} A3 dari Giza, dilakukan \textit{post-processing} untuk menghasilkan file yang dengan mudah dapat diproses untuk melakukan \textit{sense transfering}.

Berikut ini merupakan salah satu contoh pasangan kalimat pada \textit{file} A3 keluaran Giza:

\begin{lstlisting}caption={A3-File}, label={a3-file}]
# Sentence pair (47183) source length 9 target length 9 alignment score : 6.85298e-13
Undang-Undang No 14 tahun 2008 tentang Kebebasan Memperoleh Informasi 
NULL ({ }) Law ({ 1 }) No ({ 2 }) 14 ({ 3 }) of ({ }) 2008 ({ 4 5 }) on ({ 6 }) Freedom ({ 7 8 }) of ({ }) Information ({ 9 })
\end{lstlisting}

Pembacaan pasangan kata berdasarkan hasil keluaran dilakukan dengan indeks nomor kata yang berada pada dalam kurung kata di bahasa Inggris. Karena pemisah token \textit{by default} adalah spasi, maka kata "Undang-Undang" adalah kata dengan indeks nomor 1, kata "No" adalah kata dengan indeks nomor 2, dan berlaku hal yang sama sampai kata "Informasi". Pada kata bahasa inggris, "Law" dipasangkan dengan indeks satu yang mana adalah "Undang-Undang", kata "No" dipasangkan dengan indeks dua yang mana adalah "No". 

Terdapat dua buah \textit{post-processing} yang dilakukan dengan tujuan masing-masing untuk:

\begin{enumerate}
	\item Penyimpan pasangan kata-kata yang bersesuaian untuk sistem WSD.
	\item Sebagai \textit{resource} untuk proses \textit{enhancement word alignment}.
\end{enumerate}


Untuk keperluan nomor satu, bentuk \textit{output} diproses menjadi bentuk lain dengan format:

\begin{lstlisting}
<pair>kata_en_1||kata_id_1 kata_id_2</pair?##<pair>kata_en_2||kata_id\_3</pair>...</pair>
\end{lstlisting}

Contoh dari hasil \textit{post-processing} pada pasangan kalimat sebelumnya adalah:

\begin{lstlisting}
<pair>law||undang-undang</pair>##<pair>no||no</pair>##<pair>14||14</pair>##<pair>2008||tahun 2008</pair>##<pair>on||tentang</pair>##<pair>freedom||kebebasan memperoleh</pair>##<pair>information||informasi</pair>
\end{lstlisting}

Hasil ini kemudian disimpan sebagai sebuah \textit{file} sendiri yang akan digunakan kembali pada sistem WSD nantinya. Sementara itu, keperluan nomor dua difokuskan untuk membuat \textit{dictionary} yang akan ditingkatkan kualitasnya pada tahap berikutnya. Untuk menghasilkan \textit{file} yang dibutuhkan pada nomor kedua, dilakukan pengumpulan pasangan kata bahasa Indonesia dengan bahasa Inggris. Bila misalkan pada kalimat ke-n terdapat kata "undang-undang" yang dipasangkan dengan "law", dan pasangan kata "undang-undang" dengan "regulation" pada kalimat lain (kalimat ke-m, dimana m != n). Berdasarkan kedua kalimat tersebut, maka kata "undang-undang" akan berpasangan dengan dua kata yaitu "law", dan "regulation".


\section{Evaluasi \textit{Word Alignment}}

\subsection{Pre-Processing}
Pertama, dilakukan pemilihan acak terhadap 200 pasang kalimat yang merupakan hasil keluaran Giza(\textit{file} A3). Setiap pasang tersebut meliputi dua buah isi yaitu kalimat bahasa Indonesia, dan kalimat bahasa Inggris dengan tanda \textit{alignment} Giza. Proses selanjutnya adalah menyiapkan 200 pasang kalimat tersebut untuk dievaluasi oleh anotator. Terdapat beberapa proses dalam mempersiapkan data untuk evaluasi oleh anotator.
\begin{enumerate}
	\item Pertama, pada setiap kata dalam bahasa Indonesia diberikan sebuah tanda indeks berupa angka untuk mempermudah proses evaluasi anotator nantinya. Pada proses tersebut, kalimat "Aku ingin makan" sebagai perumpamaan, diubah menjadi "Aku(1) ingin(2) makan(3)". Angka tersebut diperuntukan untuk mempercepat dan mempermudah kerja anotator nanti untuk melihat pasangan kata dari kalimat bahasa Inggris.
	\item Kedua, kosongkan nomor indeks hasil \textit{alignment} Giza pada kalimat bahasa Inggris. Perumpamaan pada kalimat "NULL (\{  \}) i (\{ 1 \}) want (\{ 2 \}) to (\{  \}) eat (\{ 3 \})" akan berubah menjadi  "NULL (\{  \}) i (\{  \}) want (\{   \}) to (\{  \}) eat (\{  \})" yang nantinya akan diisi secara manual oleh anotator.
\end{enumerate}

\subsection{Proses Anotasi Data}
Setelah 200 buah pasangan kalimat(data) tersebut selesai dipersiapkan, anotator akan melakukan anotasi data (\textit{alignment}) secara manual dengan panduan yang diberikan oleh \saya. Panduan tersebut meliputi keterangan dari \textit{task word alignment}, format data yang diberikan dan cara pembacaannya, dan yang paling utama adalah cara melakukan proses \textit{alignment}. Panduan anotasi yang diberikan dapat dilihat di lampiran pada laporan ini.

\subsection{Evaluasi}
Evaluasi perhitungan \textit{precision}, \textit{recall}, f-score, dan \textit{agreement} dilakukan secara otomatis dengan program yang dibuat dengan algoritma berikut.

\begin{lstlisting}[language=Python, caption={Word Alignment Evaluation}, label={word-alignment-evaluation}]

def evaluate_bracket(list_giza, list_anotator):
	# evaluate per character
	numbers_anotator = len(list_anotator)
	numbers_giza = len(list_giza)
	match = 0
	if numbers_giza < numbers_anotator:
		# iterate through the numbers giza
		for n in list_giza:
			if n in list_anotator:
				match += 1
	else:
		# iterate through the numbers anotator
		for n in list_anotator:
			if n in list_giza:
				match += 1
	return (numbers_anotator, numbers_giza, match)

# given sentence which already been alignned from the first anotator (an1), second anotator(an2), and giza(giza)
matches, total_giza, total_anotator, total_giza_1, total_anotator_1 = 0, 0, 0, 0, 0
precision, recall = [[],[]], [[],[]]

for each sentence in sentences:
	for each token in sentence:
		(numbers_anotator, numbers_giza, match) = evaluate_bracket(an1(token), giza(token))
		(numbers_anotator_1, numbers_giza_1, match_1) = evaluate_brakcet(an2(token), giza(token))
		agreement = count_agreement(an1(token), an2(token))
		matches += match
		matches_1 += match_1
		total_giza += numbers_giza
		total_giza_1 += numbers_giza_1
		total_anotator += numbers_anotator
		total_anotator_1 += numbers_anotator_1
	agreement.append(agreement)
	precision[0].append(matches/total_giza)
	recall[0].append(matches/total_anotator)
	precision[1].append(matches_1/total_giza_1)
	recall[1].append(matches_1/total_anotator_1)

precision = average(precision[0])
recall = average(recall[0])
precision_1 = average(precision[1])
recall_1 = average(recall[1])
agreement = average(agreement)	

\end{lstlisting}

Berdasarkan cara perhitungan evaluasi tersebut, terdapat dua buah \textit{precision} dan \textit{recall} yang mana masing-masing menunjukan indikator penilaian untuk anotator pertama dan kedua.

\section{Peningkatan Kualitas \textit{Alignment}}

Hasil dari \textit{alignment} kata yang dilakukan Giza masih menghasilkan pasangan-pasangan kata yang tidak tepat. Untuk mengurangi jumlah pasangan kata yang salah tersebut, dilakukan \textit{enhancement} terhadap hasil pasangan kata dari Giza. Terdapat dua macam peningkatan kualitas \textit{alignment} yang digunakan pada penelitian ini, yaitu \textit{crawling based} dan \textit{bi-directional based}.

\subsection{Pendekatan \textit{Crawling}}

Konsep \textit{crawling} pada penelitian ini mengacu pada kebutuhan untuk \textit{filtering} hasil pasangan kata yang salah berdasarkan kamus Indonesia-Inggris. Karena keterbatasan \textit{resource digital} kamus tersebut, maka dibutuhkan pendekatan \textit{crawling} dari \textit{online dictionary} untuk mendapatkan pasangan kata yang benar. Salah satu \textit{online dictionary} yang dapat diakses dan memiliki hasil terjemahan yang cukup baik adalah \textit{website} sederet.com. \textit{Crawling} dilakukan dengan memeriksa setiap pasangan bahasa Inggris dari kata Indonesia hasil Giza, apakah pasangan kata tersebut berada pada hasil penerjemahan yang sesuai. Ilustrasi dari proses ini dapat dimodelkan dalam contoh berikut:

\begin{enumerate}
	\item Kata "halaman" memiliki pasangan bahasa Inggris hasil Giza yaitu  "\textit{courtyard}", \textit{"yard"}, \textit{"page"}, dan "\textit{lawn}".
	\item Gunakan \textit{crawler} untuk menerima hasil terjemahan dari kata "halaman" dalam bahasa Inggris
	\item \textit{Crawler} mendapatkan hasil kata "\textit{page}", dan "\textit{courtyard}".
	\item Berdasarkan kedua hasil tersebut, maka pasangan kata "halaman" yang dianggap benar adalah irisan dari kedua \textit{set} tersebut yaitu "\textit{page}" dan "\textit{courtyard}"
\end{enumerate}

\subsection{Pendekatan \textit{Bi-directional}}

Metode lain yang digunakan untuk meningkatkan kualitas \textit{aligment} yaitu dengan memanfaatkan \textit{bi-directional alignment}. Proses yang dilakukan adalah melakukan validasi terhadap kata-kata yang berpasangan  dari kedua korpus. Bagan dari \textit{enhancement} pada \textit{bi-directional} ini dapat dilihat pada gambar \ref{fig:Bidirectional-Enhancement}.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/bidirectional-enhancement}
	\caption{Bi-directional \textit{Enhancement}}
	\label{fig:Bidirectional-Enhancement}
\end{figure}

Pertama, setiap kata dalam bahasa Indonesia dikumpulkan terlebih dahulu dengan setiap pasangan kata bahasa Inggrisnya (satu kata bisa memiliki lebih dari satu pasangan). Proses selanjutnya adalah melakukan pengumpulan yang serupa terhadap kata dalam bahasa Inggris dengan pasangan kata dalam bahasa Indonesianya. Berbagai kata dalam bahasa Indonesia beserta pasangannya disimpan sebagai "kamus-1". Kata dalam bahasa Inggris, beserta pasangan kata Indonesianya disimpan sebagai "kamus-2". Proses validasi dilakukan dengan cara:

\begin{enumerate}
	\item Untuk setiap kata di bahasa Indonesia dalam "kamus-1" semisal kata "kali".
	\item Lakukan pengecekan terhadap setiap pasangan kata di bahasa Inggris pada "kamus-1" dari kata "kali", misalkan pasangan kata bahasa inggrisnya adalah "time", "river", dan "fire".
	\item Jika pada "kamus-2" kata "time" dipasangkan dengan "kali", dan "waktu" maka kata "time" merupakan pasangan yang dianggap benar (karena kata "time" berpasangan dengan "kali"). Pada kasus kata "fire", bila pasangan bahasa Indonesianya adalah "api" dan "tungku", maka kata "fire" dianggap bukan pasangan yang tepat dengan "kali" karena tidak terdapat pasangan "fire -> kali".
\end{enumerate} 

\begin{lstlisting}[language=Python, caption={Word Alignment Enhancement}, label={word-alignment-enhancement}]

dict_id = {}
dict_en = {}

# masukan setiap kosa kata bahasa Indonesia ke dalam dict_id sebagai key dan kumpulan pasangan kata bahasa inggrisnya sebagai value
# proses yang sama dilakukan untuk dict_en dengan kosa kata bahasa Inggris sebagai key dan kumpulan pasangan kata bahasa Indonesia sebagai value
# stop adalah list stopword yang didapat dari korpus nltk

# this section is for filtering which english word that has corresponding indo translation (bidirectional) from Giza output
for indo_word in dict_id.keys():
	for en_word in dict_id[indo_word].keys():
		if en_word != dict_en:
		# filtering so no same translation is entered, answer -> answer, jawaban -> jawaban
			if en_word in dict_en and indo_word in dict_en[en_word] and en_word not in stop:
				if indo_word not in final_dictionary:
					final_dictionary[indo_word] = { en_word: dict_en[word_en][word_id] }
				else:
					if en_word not in final_dictionary[indo_word]:
						final_dictionary[indo_word][en_word] = dict_en[word_en][word_id]
\end{lstlisting}

\section{\textit{Sense Transfering}}
Hasil dari proses peningkatan kualitas \textit{alignment} adalah sebuah "kamus" bahasa yang akan digunakan sebagai referensi untuk memindahkan makna kata dari bahasa Inggris ke kata yang benar pada bahasa Indonesia. Proses ini dilakukan dengan tahap-tahap sebagai berikut:

\begin{enumerate}
	\item Iterasi untuk setiap kata dalam bahasa Indonesia pada kamus
	\item Iterasi pada setiap pasangan kalimat
	\item Periksa apakah "\textit{pair}" kata bahasa Indonesia tersebut terdapat di dalam kamus
	\item Jika "pair" tersebut benar berada dalam kamus, maka pindahkan makna kata dari \textit{english word} yang bersesuaian.
\end{enumerate}

Ilustrasi dari proses tersebut pada kata "halaman" adalah sebagai berikut:

\begin{enumerate}
	\item Jika misalkan kata "halaman" pada kamus memiliki pasangan kata "page" dan "courtyard".
	\item Pada sebuah kalimat "... halaman kedua ..." dimana "\textit{pair}" pada kalimat tersebut diantaranya adalah
	\begin{lstlisting}
	..<pair>second||kedua</pair>##<pair>page||halaman</pair>..
	\end{lstlisting}
	\item Pasangan kata yang didapat dari "halaman" dari \textit{pair} tersebut adalah "page". Berdasarkan hasil tersebut kata "page" kemudian diperiksa pada kamus yang ada.
	\item Karena kata "page" merupakan salah satu terjemahan untuk kata "halaman", maka pindahkan makna "page" dari \textit{sense tagged corpus} kalimat tersebut ke kata "halaman" pada kalimat Indonesia dengan indeks yang sama.
	\item Dalam proses pemindahan makna tersebut, akan dilakukan pemeriksaan apakah untuk kata yang sama, terdapat makna kata yang serupa dari hasil transfer kalimat lain.
	\item Jika "kemiripan" makna kata yang akan dipindahkan melebihi threshold (0.5), makan akan digunakan \textit{sense key} yang lama karena kedua \textit{sense key} dianggap mempunyai makna yang sama. Penghitungan seberapa dekat "makna" dari kedua \textit{sense key} tersebut dilakukan dengan bantuan \textit{method} path\_similarity dari \textit{tool} NLTK dengan korpus wordnet.
\end{enumerate}

%-----------------------------------------------------------------------------%
\section{Sistem WSD}
Sistem WSD dibangun dengan menggunakan \textit{supervised learning}. \textit{Machine learning tool} yang digunakan untuk membangun sistem ini adalah Scikit \citep{scikit-learn}. Pada sistem ini terdapat tiga buah bagian utama yaitu pemilihan fitur serta \textit{classifier}, ekstraksi fitur, dan evaluasi hasil \textit{classifier}.

\subsection{Pemilihan Fitur dan \textit{Classifier}}
Terdapat tiga buah fitur pada penelitian ini yang terdiri dari:

\begin{enumerate}
	\item Fitur \textit{bag of words}
	\item Fitur \textit{POS tagging}
	\item Vektor dari hasil \textit{word embedding}
\end{enumerate}

\textit{Classifier} yang digunakan pada penelitian ini adalah SVM dengan \textit{library} Python yaitu Scikit dengan parameter \textit{default} berupa kernel linear dan C=1.

\subsection{Ekstraksi Fitur}
Fitur bag of words menggunakan pendekatan kemunculan kata-kata pada konteks kalimat sebagai fitur. Kata yang diambil untuk dijadikan fitur adalah dua buah kata di kiri dan di kanan dari \textit{target word}. Pada penelitian ini, kata-kata yang merupakan bagian dari \textit{stopwords} dalam bahasa Indonesia tidak dimasukan sebagai fitur. Contoh dari fitur ini dapat dilihat pada kalimat dengan kata tujuan "bisa" berikut:
\\
- Ani digigit ular dengan bisa yang berbahaya
\\
Pada contoh kalimat tersebut, \textit{bag of words} yang diambil adalah ["digigit", "ular", "berbahaya", NULL]

Setiap fitur \textit{bag of words} dari setiap kalimat tersebut dikumpulkan untuk menjadi satu fitur besar yang mendeteksi kemunculan kata-kata tersebut pada setiap kalimat.

Proses yang dilakukan dalam pengambilan kata konteks untuk fitur \textit{bag of words} dilakukan dengan tahap-tahap berikut.

\begin{lstlisting}[language=python,caption={Fitur Bag of Words}, label={fitur-bag-of-words}]

bag_of_words []

for each sentence
	split sentence by whitespace into words
	for each word
		if word == target word
			for x in [-2,-1,1,2]
				if word(x) exist and word(x) not in bag_of_words
					add word(x) into bag_of_words
					
return bag_of_words

\end{lstlisting}

Fitur POS Tagging menggunakan \textit{tool} dari Stanford bernama "A Part-Of-Speech Tagger" yang dilatih dengan menggunakan model untuk bahasa Indonesia. Proses \textit{tagging} ini dilakukan sebelum memasuki sistem WSD terhadap keseluruhan kalimat dalam korpus identik yang berisi bahasa Indonesia saja. Terdapat \textit{pre-processing} awal pada korpus bahasa Indonesia tersebut untuk menghilangkan beberapa tanda baca seperti titik, koma, tanda tanya, tanda seru, dan beberapa tanda baca lainnya. Setelah proses tersebut, diberikan tanda baca berupa titik pada akhir kalimat sebagai indikator akhir sebagai kebutuhan dari kompabilitas \textit{tool} (tidak semua kalimat pada korpus memiliki tanda baca akhir kalimat). Perintah yang dilakukan untuk melakukan \textit{POS Tagging} tersebut adalah:

\begin{lstlisting}[language=bash,caption={Stanford POS Tagger}, label={stanford-pos-tagger}]

java -mx300m -cp 'stanford-postagger.jar:lib/*' edu.stanford.nlp.tagger.maxent.MaxentTagger -model <model_bahasa_indonesia> -textFile <korpus_bahasa_indonesia>

\end{lstlisting}

Hasil dari proses tersebut merupakan korpus dengan setiap kata yang sudah memiliki POS Tag dengan format:

\begin{lstlisting}
<kata_1>_<postag_1> <kata_2>_<postag_2> ... <kata_n>_<postag_n>
<kata_x> <postag_x> <kata_y>_<postag_y> ... <kata_z>_<postag_z>
...
\end{lstlisting}

Kelas kata yang diambil adalah POS Tag dari \textit{target word} kata sebelum, dan kata sesudahnya. Kelas kata dari \textit{target word} diperhitungkan karena pada beberapa kasus kata polisemi dapat dibedakan maknanya berdasarkan POS Tag yang dimilikinya. POS Tag yang digunakan mengacu pada kelas-kelas yang ada pada POS Tag Penn Treebank seperti NN(Noun), NNP(Proper Noun), VB(verb), CC(Coordinating conjunction), dan lain-lain. Pembentukan kelas POS Tag untuk menjadi fitur dilakukan dengan proses yang serupa pada fitur \textit{bag of words} dimana kombinasi kombinasi dari POS Tag yang mungkin direpresentasikan dalam \textit{one hot representation}. Hal ini dapat diilustrasikan dengan proses berikut:

\begin{enumerate}
	\item Simpan POS Tag dari indeks kata masing-masing (\textit{target word}-1, \textit{target word}, \textit{target word}+1)
	\item Untuk masing-masing indeks baik itu -1,0,dan 1
	\item Kumpulkan POS Tag yang \textit{distinct}, populasikan dalam \textit{array}
	\item \textit{Array} ini nantinya akan merepresentasikan keberadaan POS Tag tertentu pada kata dengan indeks terkait tersebut
\end{enumerate}

Fitur ketiga yang dicoba adalah \textit{word embedding}. Model dari \textit{word embedding} yang digunakan sudah dilatih dengan menggunakan korpus Wikipedia bahasa Indonesia. Vektor \textit{word embedding} yang dijadikan fitur adalah vektor dari semua kata pada kalimat tersebut. Semua vektor nilai dari kata-kata tersebut kemudian dikonkatenasi menjadi satu buah vektor besar. Untuk menjamin panjang vektor yang sama untuk setiap kalimat, panjang vektor disesuaikan dengan kalimat terpanjang dari semua kalimat yang mengandung \textit{target word} tersebut. Proses tersebut dapat diilustrasikan pada gambar berikut:

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/we-vector}
	\caption{Ilustrasi Fitur Word Embedding}
	\label{fig:Ilustrasi-Fitur-Word-Embedding}
\end{figure}


\subsection{Evaluasi Sistem}
\textit{Target word} untuk evaluasi dipilih secara manual yang memenuhi kriteria bahwa kata tersebut memiliki kata \textit{translation} lebih dari satu dengan makna yang berbeda.Evaluasi dilakukan dengan \textit{cross validation} menggunakan perhitungan F1-score dari hasil klasifikasi yang dilakukan \textit{classifier} terhadap \textit{target word}. \textit{Cross validation} dilakukan dengan iterasi sebanyak tiga kali dengan perbandingan antara \textit{training} dan \textit{test set} sebesar 0,7:0,3.

Sebuah algoritma sederhana digunakan sebagai \textit{baseline} untuk pembanding dari sistem WSD yang dibangun. Baseline menggunakan pendekatan \textit{most frequent sense} sebagai cara untuk menentukan makna terbaik dari suatu kata. Bila diberikan \textit{training data} untuk kata "bisa" dengan makna "dapat melakukan" sebanyak 4 buah dan makna "racun ular" sebanyak 6 buah, maka algoritma baseline ini akan mengklasifikasikan semua kata "bisa" menjadi "racun ular".

