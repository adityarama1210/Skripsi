%!TEX root = skripsi.tex
%-----------------------------------------------------------------------------%
\chapter{\babDua}
%-----------------------------------------------------------------------------%
Bab ini membahas mengenai studi literatur yang digunakan selama penelitian. Studi literatur ini menjelaskan tentang hal-hal mendasar yang dibutuhkan dalam penelitian.
%-----------------------------------------------------------------------------%

\section{Semantik Leksikal}

Kata dalam suatu bahasa memiliki banyak fitur atau informasi yang terkandung di dalamnya. Informasi pada kata tersebut meliputi contoh-contoh seperti ortografi, POS Tag, dan juga makna kata. Informasi yang ada tersebut dapat dipergunakan sebagai fitur untuk merepresentasikan suatu kata.

\subsection{Fitur Kata}
Terdapat berbagai macam fitur yang dapat diambil dari informasi sebuah kata. Informasi ini meliputi bentuk-bentuk variasi kata, kelas kata, makna kata, dan lain-lain. Ortografi, sebagai salah satu fitur kata meliputi permasalahan dalam suatu kata pada bahasa mengenai ejaan, kapitalisasi, pemenggalan kata, dan lain-lain. Pada bentuk kata (morfologi), Lemma merupakan bentuk kata "dasar" seperti misalnya "\textit{run}", \textit{"ran"}, dan "\textit{runs}" memiliki lemma yang sama yaitu "run". POS Tag atau Part of Speech Tag merupakan "kategori" dari suatu kata yang didefinisikan untuk membedakan kelas-kelas yang ada seperti misalnya \textit{proper noun} (nama orang, organisasi, nama tempat, dan lain-lain), \textit{verb} (kata kerja), \textit{adjective} (kata sifat seperti "marah", "senang", dan lain-lain), \textit{adverbial}, dan semacamnya. \textit{Tool} yang digunakan untuk melakukan POS Tagging pada penelitian ini adalah \textit{tool} dari Stanford. Makna kata menyimpan informasi dari arti sebuah kata, dan satu kata bisa memiliki lebih dari satu makna. Selain informasi dalam suatu kata, terdapat relasi antara satu kata dengan kata lain seperti misalnya sinonim, homonim, polisemi, dan lain-lain. Berdasarkan informasi \citep{sheeba2013unsupervised}, sinonim merupakan relasi pada kata-kata yang berbeda namun memiliki makna yang serupa, dan homonim merupakan kata dengan ejaan atau penulisan yang sama namun memiliki makna yang berbeda. Mirip dengan homonim, polisemi merupakan suatu kata yang memiliki makna lebih dari satu. Contoh dari relasi sinonim adalah antara kata "bohong" dengan "dusta", "perspektif" dengan "sudut pandang", dan kata-kata dengan makna mirip lainnya. Contoh dari kata polisemi adalah pada kata "darah" dalam kalimat "Tangan Ani mengeluarkan darah setelah tertusuk jarum" dengan "Ani baru menyadari bahwa dia dan Rina memiliki hubungan darah". Relasi homonim antar kata dapat dilihat misalnya pada kata "rapat" yang dapat berarti "pertemuan" ataupun juga "berdekatan", sebenarnya kata ini merupakan dua buah kata yang berbeda(sehingga maknanya berbeda) hanya saja penulisan dan pengejaannya sama.

Terdapat beberapa cara untuk merepresentasikan sebuah kata sebagai fitur. Salah satu cara yang sederhana adalah dengan merepresentasikan kata sebagai \textit{one hot vector}. Pada model ini, setiap kata di dalam sebuah korpus diberikan nomor indeks untuk membangun vektor yang mewakili keberadaan kata tersebut. Jika terdapat sebuah kata yang muncul pada konteks yang ingin direpresentasikan, indeks vektor yang sama dengan indeks kata tersebut akan bernilai 1. Bila terdapat sebuah korpus dengan jumlah kata unik berjumlah 4 dengan kata-kata "Ani", "marah", "kemarin", dan "malam" (sebuah vektor dengan pangjang empat). Representasi \textit{one hot vector} untuk kalimat "Ani marah" dapat ditulis dengan vektor [1,1,0,0].

Representasi \textit{one hot vector} akan mempunyai panjang vektor yang besar jika korpus mempunyai jumlah kata unik yang besar. Terdapat bentuk representasi lain untuk membentuk vektor dari kata, salah satunya adalah dengan \textit{word embedding}. \textit{Word Embedding} menggunakan representasi bilangan \textit{real} pada vektor untuk merepresentasikan sebuah kata berdasarkan hasil \textit{training} dengan suatu korpus. Contoh representasi dari \textit{word embedding} pada suatu kata "makan" adalah vektor [0.6, -0.3, ..., 0.5] (misalnya). Vektor dari hasil \textit{word embedding} mempunyai karakteristik di mana jarak antara dua buah vektor dari kata yang mirip secara semantik bernilai kecil(dekat). Bila misalkan pada data \textit{training} untuk \textit{word embedding} terdapat banyak kalimat-kalimat berbentuk "... makan Y ..." di mana Y adalah sebuah objek berupa makanan. Maka kata-kata yang mewakili Y seperti misalnya "burger", "apel", "steak", dan lain-lain, akan memiliki vektor yang mirip dan secara implisit dapat saling menggantikan untuk menempati posisi Y tersebut. Berdasarkan keterdekatan vektor tersebut, \textit{word embedding} mampu untuk menangkap semantik dari kata-kata yang ada pada korpus.

Salah satu model \textit{word embedding} yang dapat digunakan adalah Word2Vec \citep{mikolov2013distributed}. Pada penelitian ini Word2Vec akan digunakan untuk memanfaatkan vektor \textit{word embedding} sebagai salah satu fitur percobaan skenario yang ada. 

\subsection{Wordnet}

Wordnet merupakan \textit{online lexical database} yang didesain dan untuk digunakan suatu program \citep{miller1995wordnet}. Salah satu Wordnet untuk bahasa Inggris yang sudah berkembang dan digunakan dalam berbagai penelitian adalah Wordnet yang dikembangkan Princeton (PWN atau Princeton Wordnet). Selain Wordnet bahasa Inggris, terdapat juga Wordnet Bahasa Indonesia yaitu Wordnet bahasa Indonesia dari Fakultas Komputer Universitas Indonesia (Wordnet UI) , dan Wordnet hasil penelitian pembuatan Wordnet Bahasa \citep{noor2011creating} (Wordnet Bahasa). Pada Wordnet UI terdapat sebanyak 1.203 synset, 1.659 kata unik, dan 2.261 relasi di dalamnya. Sementara itu, Wordnet Bahasa memiliki 49.668 synset, 145.696 \textit{senses}, dan 64.431 kata unik. Hal ini menunjukkan bahwa Wordnet Bahasa memiliki informasi lebih banyak dari Wordnet UI, walaupun jumlah tersebut juga mencakup beberapa kata dalam bahasa Malaysia atau Melayu. Representasi yang digunakan Wordnet adalah \textit{set of synonyms} (synset) sebagai kumpulan dari kata-kata yang memiliki kemiripan makna. Selain menyimpan kata-kata, Wordnet juga menyimpan makna dari setiap kata-kata tersebut. Informasi makna kata yang ada di dalam Wordnet sering digunakan untuk sistem WSD suatu bahasa sebagai acuan (\textit{sense inventory}). Makna kata pada Wordnet disimpan dengan \textit{uniq identifier} berupa \textit{sense key} yang memiliki format "\textbf{lemma\%key}". Salah satu contoh \textit{sense key} adalah "home\%1:06:00::" yang mana memiliki makna "\textit{Housing that someone is living in}". Representasi \textit{synset} dari Wordnet beserta relasi-relasinya tersebut dapat dimanfaatkan untuk disambiguasi makna suatu kata.

%-----------------------------------------------------------------------------%
\section{Word Sense Disambiguation}
%-----------------------------------------------------------------------------%
\textit{Word Sense Disambiguation} merupakan salah satu penelitian di bidang NLP yang bertujuan untuk menentukan makna yang paling tepat dari suatu kata berdasarkan konteks kata tersebut ditemukan. Sebagaimana kata dalam suatu bahasa bisa memiliki makna lebih dari satu (polisemi), \textit{task} ini akan menentukan makna kata mana yang paling tepat. 

Penentuan makna kalimat dilakukan dengan pemberian informasi berupa kata yang menjadi \textit{target} dan konteks berupa kalimat. Contoh proses disambiguasi yang dilakukan untuk kata \textbf{cokelat}:

\begin{lstlisting}[backgroundcolor = \color{white}]
K1: Roni memakan cokelat yang diberikan ibunya
K2: Walaupun mobil cokelat itu mahal, dia sangat ingin membelinya
\end{lstlisting}


Pada kalimat pertama (K1), \textbf{cokelat} yang dimaksud memiliki makna sebagai makanan yang terbuat dari buah \textit{cokelat}. Sementara itu, Kata \textbf{cokelat} pada kalimat kedua (K2) memiliki makna yang berbeda, di mana kata tersebut merupakan satu keterangan warna. Penentuan makna yang tepat dapat dilakukan dengan bantuan informasi konteks dari kalimat di mana kata tersebut muncul. Pada K1, kata \textbf{memakan} memberikan informasi bahwa \textit{cokelat} yang dimaksud adalah objek yang bisa dimakan. Kata yang memberikan informasi pada kalimat kedua adalah kata \textbf{berwarna} yang secara eksplisit menerangkan bahwa \textbf{cokelat} yang dimaksud adalah warna. Namun demikian, konteks maupun informasi yang bisa diambil dari kalimat tidak selalu eksplisit. Pada contoh kalimat seperti "Pohon cokelat tua di belakang rumahku sangat besar", cokelat yang dimaksud bisa bermakna "buah cokelat yang sudah tua" atau "berwarna cokelat tua".

Penentuan makna kata yang tepat oleh sistem WSD ditentukan berdasarkan konteks dari kata tersebut berada. Walaupun satu kata dapat memiliki beberapa makna, terdapat kecil kemungkinan bahwa kata yang sama digunakan dalam satu \textit{discourse} (konten dari sebuah percakapan atau bahasan) untuk menyatakan makna yang berbeda sebagaimana "\textit{one sense per discourse}" \citep{gale1992one}.

Pada umumnya, sistem WSD yang dibangun dapat menggunakan pendekatan \textit{machine learning} baik itu \textit{supervised}, \textit{semi-supervised}, maupun \textit{unsupervised}. Pendekatan yang dipilih biasanya bergantung pada data maupun \textit{resource} yang dimiliki pada suatu bahasa. Jika terdapat data/\textit{resource} yang memadai, sistem dengan pendekatan \textit{supervised} biasanya dilakukan untuk mendapatkan akurasi yang optimal. Namun demikian, untuk bahasa-bahasa dengan data/\textit{resource} yang kurang memadai, pendekatan \textit{semi-supervised} atau bahkan \textit{unsupervised} dapat dimanfaatkan untuk mendapatkan makna kata secara otomatis. 

Terdapat dua buah granularitas dalam sistem WSD yaitu \textit{coarse-grain} dan \textit{fine-grain}. Coarse-grained WSD lebih berfokus pada kata-kata yang homonim. Sementara itu, fine-grained WSD menggunakan kata-kata yang bersifat polisemi seperti misalkan disambiguasi dari kata "bulan" pada "bulan langit malam" dengan "bulan September". Pada fine-grained WSD, kata-kata yang ambigu lebih banyak dari pada coarse-grained, yang mana mengakibatkan lebih sulitnya klasifikasi yang dilakukan oleh sistem untuk menentukan makna kata yang tepat.\textit{Agreement} yang dihasilkan antar anotator pada fine-grained WSD sendiri juga relatif rendah \citep{navigli2007semeval}. Pelabelan makna yang lebih detail dari fine-grained WSD dapat dilihat pada gambar berikut.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/coarse-fine}
	\caption{coarse dan fine-grained WSD  \citep{shen2013coarse}}
	\label{fig:coarse}
\end{figure}

Berdasarkan gambar \ref{fig:coarse}, dapat dilihat bahwa kata "\textit{atmosphere}" yang awalnya hanya dipandang sebagai 3 buah makna, dapat dipecah lagi menjadi beberapa makna yang lebih detail. Lebih banyaknya \textit{sense} yang dihasilkan mengakibatkan lebih sulitnya klasifikasi yang dilakukan dalam sistem WSD fine-grained.

Pada sistem WSD, fitur yang umum digunakan beberapa di antaranya adalah konteks kata baik dengan pendekatan Collocation dan Co-occurrence, POS Tag kata, vektor \textit{word embedding} kata. Fitur Co-occurrence lebih berfokus pada kemunculan kata pada suatu konteks baik itu dokumen, paragraf, atau kalimat. Contoh dari fitur dengan pendekatan ini adalah pada kalimat "Dia membuka halaman empat dari buku harry potter", di mana kata-kata yang ada pada kalimat tersebut dapat menjadi fitur yang menandakan keberadaan suatu kata. Pada contoh tersebut, setiap kata dapat ditandai sebagai angka 1 pada vektor 1 dan 0 jika kata tersebut muncul. Sementara Collocation lebih berfokus pada kata yang sering muncul secara bersama-sama dan kecil kemungkinannya untuk muncul bersama secara kebetulan. Jika pada contoh kalimat yang sama, fitur co-occurence hanya melihat pada kata-kata di dekat kata "halaman" (misalkan kata ini sebagai \textit{target word}), yang muncul sering dengan kata "halaman" tersebut. Pada fokus fitur ini, kata "buku" memiliki kemungkinan lebih besar untuk berada dekat dengan kata "halaman" dan kecil kemungkinan untuk muncul secara kebetulan.

\subsection{WSD Bahasa Inggris}
Terdapat berbagai penelitian yang sudah dilakukan untuk melakukan disambiguasi kata pada Bahasa Inggris. Penelitian WSD pada Bahasa Inggris sendiri lebih banyak dibandingkan dengan Bahasa Indonesia karena permasalahan WSD ini diangkat dalam beberapa \textit{event} seperti SemEval ataupun Senseval. \textit{Resource} yang digunakan sebagai \textit{sense inventory} utama pada WSD Bahasa Inggris biasanya adalah Wordnet princeton, dan beberapa data tambahan seperti misalnya Brown Corpus, SemCor, dan lain-lain. Terdapat salah satu sistem WSD yang sudah dipublikasikan dan siap digunakan untuk melakukan WSD dengan \textit{input} berupa \textit{free text} dalam Bahasa Inggris. Sistem WSD tersebut adalah "It Makes Sense" (IMS) yang dibangun oleh Zhi Zhong dan Hwee Tou Ng \citep{zhong2010makes}. Sistem  dibangun menggunakan pendekatan \textit{supervised learning} yang dapat digunakan untuk semua kata bahasa Inggris. Pada dasarnya, \textit{classifier} yang dipilih untuk \textit{task} ini adalah \textit{support vector machine} (SVM). Arsitektur yang dibangun pada IMS dapat dilihat pada gambar berikut:

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/Arsitektur-IMS}
	\caption{Arsitektur IMS}
	\label{fig:Arsitektur-IMS}
\end{figure}

Proses \textit{pre-processing} pada IMS dilakukan dengan empat tahapan:
\begin{enumerate}
	\item Mendeteksi batasan kalimat dengan \textit{sentence splitter}
	\item Tokenisasi dengan \textit{tokenizer}
	\item POS Tagging untuk semua token
	\item Mengubah token menjadi lemma dengan \textit{lemmatizer}
\end{enumerate}

Ekstraksi fitur dilakukan dengan mengombinasikan:

\begin{enumerate}
	\item POS Tag dari tiga buah kata di kiri dan kanan \textit{target word}, serta kata itu sendiri. 
	\item Kata-kata sekitar pada konteks kalimat ataupun kalimat tetangganya. Kata-kata yang terkandung di dalam \textit{stopwords} dan memiliki simbol atau angka dibuang dari kalimat tersebut. Kata-kata yang tersisa tersebut kemudian diubah menjadi bentuk kata dasarnya dalam huruf kecil.
	\item \textit{Local Collocation} dengan 11 buah \textit{collocation} baik itu sebelum \textit{target word} maupun setelahnya. 
\end{enumerate}

Pengujian seberapa baik performa IMS dalam melakukan  WSD \textit{task} mendapatkan hasil:

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/Performa-IMS}
	\caption{Performa IMS \citep{zhong2010makes}}
	\label{fig:Performa-IMS}
\end{figure}

IMS digunakan pada penelitian ini karena sistem WSD ini sudah dapat digunakan untuk \textit{tagging} makna kata dengan input berupa \textit{free text}.

\subsection{WSD Bahasa Indonesia}

Terdapat dua penelitian terkait WSD Bahasa Indonesia yang ditemukan, yaitu penelitian WSD menggunakan data dari situs berita Kompas \citep{uliniansyah2006word}, dan \textit{cross lingual} WSD \citep{septiantri2013wsd}. Penelitian \citep{uliniansyah2006word} menggunakan Naive Bayes untuk klasifikasi \textit{sense} dengan fitur-fitur berupa satu kata di kiri dan kanan \textit{target}, kata kerja terdekat dari \textit{target}, konteks dokumen, dan kata kerja transitif di sekitar \textit{target word}. Sistem WSD yang dibangun tersebut memiliki hasil akurasi pada \textit{range} 73-99\%.

Pada penelitian dengan pendekatan \textit{cross lingual} WSD \citep{septiantri2013wsd}, proses diawali dengan mendapatkan makna kata dengan memanfaatkan korpus paralel dwibahasa. Proses ekstraksi makna kata tersebut akan dijelaskan pada sub-bab \textit{cross language} dalam pembahasan \textit{Word Sense Induction}. Setelah makna kata didapatkan, kata-kata yang memilki makna lebih dari satu diambil untuk dijadikan \textit{sample} untuk mengevaluasi sistem WSD yang dibangun. Setelah mendapatkan kata-kata yang ambigu, proses selanjutnya adalah mengambil fitur dari masing-masing konteks kata tersebut muncul. Ekstraksi fitur yang dilakukan adalah mengambil kata-kata yang pernah muncul pada kalimat yang mengandung \textit{target word}. Dari hasil kata-kata tersebut, vektor fitur akan direpresentasikan dengan cara yang serupa seperti \textit{bag of words} yaitu dengan vektor satu dan nol yang merepresentasikan ada tidaknya suatu kata dalam kalimat. Terdapat beberapa \textit{classifier} yang digunakan untuk dijadikan perbandingan yaitu Naive Bayes, Random Forest, dan SVM. Variasi dari seknario pada penelitian tersebut meliputi \textit{stemming}, penghilangan \textit{stopwords}, dan modifikasi korpus paralel dengan cara menambahkan data tambahan. Secara garis besar, akurasi yang didapatkan pada penelitian tersebut adalah ketiga buah \textit{classifier} yang dicoba dapat menghasilkan tingkat akurasi yang lebih baik dari baseline.

Penelitian \textit{cross lingual} WSD \citep{septiantri2013wsd} tersebut memiliki tujuan utama untuk mencoba pendekatan \textit{cross lingual} dalam melakukan \textit{transferring} makna kata, lalu melakukan disambiguasi terhadap makna tersebut dengan kata-kata yang sudah dipilih. Berbeda dengan penelitian tersebut, fokus dari penelitian ini adalah untuk membangun \textit{sense tagged corpus} Bahasa Indonesia dengan pendekatan yang \textit{transferring} yang mirip namun berbeda. Jika pada penelitian \citep{septiantri2013wsd} menentukan makna kata dilakukan dengan melihat \textit{sense key} yang sama (\textit{intersection}) dari kata dalam kedua bahasa, penentuan makna kata dalam penelitian ini dilakukan dengan memanfaatkan \textit{sense tagged corpus} Bahasa Inggris untuk kata-kata pada korpus Inggris, kemudian \textit{transfer} makna tersebut ke kata dalam Bahasa Indonesia yang menjadi pasangannya.
%-----------------------------------------------------------------------------%
\section{Word Sense Induction}
%-----------------------------------------------------------------------------%	
%-----------------------------------------------------------------------------%	
\textit{Word Sense Induction} (WSI) adalah sebuah \textit{task} yang mempunyai fungsi utama untuk mendapatkan makna kata dari sebuah korpus atau teks yang belum dianotasi secara otomatis. WSI dapat dilakukan jika penelitian WSD yang ingin dilakukan tidak mempunyai cukup \textit{resource} seperti misalnya Wordnet ataupun \textit{sense tagged corpus} yang \textit{reliable}. \textit{Reliable} pada hal ini dapat berarti kurangnya jumlah \textit{sense} pada data, ataupun masih sedikitnya jumlah kata-kata yang ada pada Wordnet. WSI secara tidak langsung dapat memperbanyak data yang dapat digunakan jika sistem WSD yang ingin dibangun membutuhkan data \textit{training} yang tidak sedikit. Terdapat berbagai macam pendekatan dalam melakukan \textit{sense induction}, di antaranya adalah dengan melakukan \textit{clustering} kata \citep{denkowski2009survey}, ataupun menggunakan pendekatan \textit{cross language}.
	
	\subsection{Pendekatan \textit{Clustering}}
	Dua kata dianggap dekat secara semantik jika memiliki \textit{co-occurrence} dengan kata-kata tetangganya yang sama \citep{nasiruddin2013state}. Konsep tersebut mendasari cara WSI mendapatkan \textit{sense} kata secara implisit berdasarkan hasil \textit{cluster} yang terbentuk dari data atau teks mentah (teks yang tidak dianotasi).
	
	Penarikan makna secara implisit dapat dicontohkan pada beberapa kalimat rujukan berikut \citep{denkowski2009survey}:
	
	\begin{enumerate}
		\item A bottle of tezg\"{u}no is on the table.
		\item Everyone likes tezg\"{u}no.
		\item Tezg\"{u}no makes you drunk.
		\item We make tezg\"{u}no out of corn.
	\end{enumerate}
	
	Walaupun belum terdapat informasi eksplisit makna dari tezg\"{u}no, dapat disimpulkan bahwa tezg\"{u}no mengacu pada minuman beralkohol yang memabukkan. Penarikan kesimpulan ini didapatkan dari kemunculan kata tersebut dengan kata lain pada konteks yang sama.
	
	Pada pendekatan \textit{clustering} ini, makna kata bisa didapatkan secara implisit dari hasil \textit{cluster} yang terbentuk, namun demikian pelabelan yang dilakukan untuk menentukan apa yang direpresentasikan \textit{cluster} tersebut merupakan sebuah \textit{task} tersendiri.
	
	Salah satu cara \textit{clustering} yang dijelaskan \citep{pantel2002discovering} adalah dengan mencoba beberapa algoritma seperti K-Means, Buckshot, CBC, Unicon, Bisecting K-Means, dan Average Link untuk fitur yang ditentukan. Fitur yang digunakan adalah vektor dari kata yang didapatkan dengan menghitung \textit{discounted pointwise mutual information} dari kata tersebut pada konteks kata itu muncul. Perhitungan \textit{similarity} antara dua buah kata dihitung dengan menghitung jarak vektor kedua kata tersebtu.
	
	Pada pendekatan \textit{clustering}, hasil dari \textit{cluster} yang didapat masih harus diberikan label dan makna kata tidak bisa secara eksplisit diambil dari hasil tersebut. Proses \textit{topic modeling} masih diperlukan untuk dapat menentukan "topik" apa yang menggambarkan atau merepresentasikan \textit{cluster} tersebut. 
	
	\subsection{Pendekatan \textit{Cross Language}}
	Selain pendekatan \textit{clustering}, WSI juga dapat memanfaatkan fitur di mana satu kata dari suatu bahasa, dapat diterjemahkan menjadi beberapa kata di bahasa lain. Contoh kasus tersebut dapat dilihat pada kata "halaman" berikut:

	\begin{lstlisting}[backgroundcolor = \color{white}]
	(K1-Indonesia): Aku membaca 10 halaman buku Harry Potter
	(K1-English): I read 10 pages of Harry Potter book
	(K2-Indonesia): Ani tinggal di rumah dengan halaman yang sangat luas
	(K2-English): Ani lives in a house with very large yard
	\end{lstlisting}
	
	Berdasarkan kedua pasangan kalimat tersebut, kata \textbf{halaman} dalam bahasa Indonesia dapat diterjemahkan menjadi dua buah kata dalam bahasa Inggris, yaitu \textit{page} ataupun \textit{yard}. Hal ini menunjukan bahwa terjemahan dari suatu kata bergantung pada konteks di mana kata tersebut muncul.
	
	Salah satu penelitian yang juga menggunakan pendekatan \textit{Cross-Lingual} WSI adalah penelitian \citep{septiantri2013wsd} yang memanfaatkan korpus paralel untuk menentukan makna yang tepat dari suatu kata berdasarkan makna tersebut dalam Bahasa Indonesia dan Bahasa Inggris. Proses yang digunakan untuk menentukan makna kata secara \textit{cross lingual} pada penelitian tersebut dilakukan dengan tahap-tahap:
	
	\begin{enumerate}
		\item Lakukan pemasangan kata-kata antara kedua korpus (Bahasa Inggris - Indonesia) dengan Giza++
		\item Untuk kata-kata pada setiap pasangan tersebut, berikan \textit{tag} makna kata yang mungkin dari Wordnet NTU. Contoh dari proses ini misalnya pada pasangan kata "halaman" dengan "\textit{page}". Berikan \textit{sense id} yang mungkin untuk kata "halaman" dari Wordnet NTU misalnya sense-id-1, sense-id-2, dan sense-id-3. Lakukan hal yang sama pada kata "\textit{page}", misalnya diberikan \textit{sense id} sense-id-5, sense-id-7, dan sense-id-2.
		\item Berdasarkan hasil \textit{sense id} dari proses sebelumnya, ambil \textit{sense id} yang beririsan untuk dijadikan \textit{tag} dari \textit{sense} kata tersebut. Pada contoh kata "halaman" dan "\textit{page}" tadi, maka label/\textit{tag} yang diberikan pada kata "halaman" adalah \textit{sense id} sense-id-2.
		\item Lakukan proses pelabelan \textit{tagging} makna kata tersebut untuk pasangan kata lainnya.
		\item Suatu kata yang memiliki \textit{sense id} lebih dari satu kemudian dinyatakan sebagai kata yang ambigu.
	\end{enumerate}


\section{Korpus Paralel dan \textit{Comparable}}
Terdapat dua macam korpus bilingual yang dapat dimanfaatkan untuk pemanfaatan \textit{cross language } WSD yaitu korpus paralel dan \textit{comparable}. Perbedaan utama terhadap kedua buah korpus berada pada seberapa identik kedua buah konteks yang dimilikinya. Korpus paralel memiliki kalimat dan kata-kata yang serupa antara dua buah pasangan di masing-masing korpus. Hal ini dapat dicontohkan misalnya dengan kalimat satu pada korpus bahasa Indonesia "Aku makan" dengan "I eat" pada korpus bahasa Inggris. Salah satu contoh korpus paralel adalah Catholic Bible yang dinamakan sebagai bitext \citep{rudnick2011towards} yang merupakan kitab katolik dalam bahasa yang berbeda. Berbeda dengan korpus paralel, \textit{comparable} berarti kedua kalimat atau \textit{instance} yang berpasangan hanya sebatas mirip/sama dalam suatu kategori kriteria tertentu. Dengan adanya korpus paralel dan \textit{comparable} tersebut, dibutuhkan juga alat untuk menyelaraskan (\textit{aligning}) konten pada kedua korpus tersebut. \textit{Alignment} yang dapat dilakukan memiliki beberapa tingkatan mulai dari \textit{scope} yang besar sampai kecil. \textit{Scope} besar tersebut meliputi \textit{alignment} dokumen yang mana fungsinya adalah menyelaraskan antar dokumen yang konten atau kriterianya sama. Tingkatan yang lebih kecil berikutnya yaitu kalimat di mana \textit{alignment} dilakukan pada \textit{level} kalimat (pasangan kalimat yang makna atau kriterianya sama). \textit{Alignment} dengan tingkatan yang lebih spesifik lagi adalah kata (\textit{word alignment}), di mana hasil yang didapat dari proses ini adalah pasangan kata pada kedua korpus dwibahasa yang selaras. Korpus paralel maupun \textit{comparable} ini dapat dimanfaatkan untuk sistem terkait  \textit{cross language information retrieval} (CLIR), \textit{machine translation} (MT), CLWSD, dan lain-lain.
%-----------------------------------------------------------------------------%
\section{\textit{Word Alignment}}
Tugas dari \textit{word alignment} adalah menemukan korespondensi antara kata pada teks paralel 
\citep{mihalcea2003evaluation}. Pada dasarnya, \textit{task} ini diperlukan sebagai salah satu proses dalam MT untuk mendapatkan secara otomatis kata-kata yang berpasangan dari korpus paralel dwibahasa atau lebih. Secara umum, proses dari pemasangan kata berlangsung seperti pada gambar \ref{fig:word-alignment}.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/wordalignment.jpeg}
	\caption{Contoh \textit{word alignment}}
	\label{fig:word-alignment}
\end{figure}

Kasus yang dapat terjadi pada proses \textit{alignment} ini salah satunya adalah ketika terdapat kata yang tidak memiliki pasangan. Contoh dari kasus tersebut dapat dilihat pada gambar \ref{fig:word-alignment-2}.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/contoh_word_alignment_2.png}
	\caption{Contoh lain \textit{word alignment}}
	\label{fig:word-alignment-2}
\end{figure}

Bila melihat bahasa Indonesia sebagai sumber bahasa, maka kata "segalanya" pada kalimat tersebut tidak memiliki pasangan dalam bahasa Inggris K1. Pada kasus-kasus seperti ini, biasanya akan ada token khusus yang nantinya akan berpasangan dengan kata-kata yang tidak mempunyai pasangan.

\textit{Tool} yang digunakan untuk keperluan \textit{word alignment} pada penelitian ini adalah Giza++ \citep{och03:asc}. \textit{Tool} tersebut merupakan salah satu \textit{word alignment tools} pada \textit{statistical machine translation} (SMT) yang dapat digunakan untuk memasangkan kata-kata pada dua buah korpus dwibahasa atau lebih. Terdapat beberapa \textit{word alignment tools} lain seperti Berkeley \textit{aligner}, anymalign, dan lain-lain.
%------------------------------------------- ----------------------------------%

\section{Support Vector Machine}
Salah satu \textit{classifier} yang dapat digunakan dalam \textit{supervised learning} untuk melakukan klasifikasi adalah SVM. SVM termasuk sebagai metode klasifikasi yang populer dan telah digunakan untuk berbagai permasalahan seperti klasifikasi teks, \textit{facial expression recognition}, analisis gen, \textit{word sense disambiguation}, dan lain-lain. SVM dapat dikatakan sebagai salah satu metode yang membangun aturan yang dinamakan sebagai \textit{linear classifier} yang secara teori akan menghasilkan kualitas prediksi dari \textit{unseen data} yang baik \citep{fradkin2006support}. Pada salah satu penelitian WSD Bahasa Inggris \citep{zhong2010makes}, SVM digunakan sebagai \textit{classifier} dari sistem yang dibangun.

Konsep dari cara SVM bekerja adalah dengan menemukan sebuah \textit{hyperplane} dengan \textit{margin} (jarak dari \textit{hyperplane} dengan titik kelas terdekat) yang terbesar. Pemilihan \textit{margin} dengan nilai terbesar ini ditujukan agar \textit{classifier} lebih optimal dalam memisahkan objek dengan kelas yang berbeda. Pada penelitian kali ini, SVM yang digunakan berasal dari \textit{library} Python bernama Scikit \citep{scikit-learn}.

\section{Evaluasi}

Precision, Recall, dan F-score merupakan beberapa cara perhitungan untuk merepresentasikan akurasi dari suatu sistem. Berdasarkan domain \textit{information retrieval}, precision merupakan perbandingan dari total jumlah dokumen relevan yang didapatkan oleh sistem dengan total jumlah dokumen yang didapat. Lain halnya dengan precision, recall membandingkan total dokumen relevan yang didapatkan dengan total dokumen relevan dalam \textit{database} \citep{ting2011precision}. Kedua penilaian ini juga digunakan pada sistem yang melakukan klasifikasi suatu \textit{instance} dengan kelas-kelas yang sudah ditentukan.

Pada kasus \textit{word alignment}, terdapat empat buah pengukuran yang dapat dilakukan yaitu \textit{precision}, \textit{recall}, \textit{f-measure}, dan \textit{alignment error rate (AER)} \citep{mihalcea2003evaluation}. Diberikan hasil \textit{alignment} dari program berupa A, dan \textit{gold standard alignment} dari \textit{evaluator} (manusia) sebagai G, masing-masing mengandung dua buah \textit{set} yaitu \textit{probable alignment} dan \textit{sure alignment}. Karena \textit{tool alignment} yang digunakan pada penelitian ini menghasilkan \textit{sure alignment} untuk setiap pasangan, maka dilakukan penyesuaian formula penghitungan seperti rumus pada (2.1).

\begin{equation}
\begin{split}
Precision = A \cap G / A \\
Recall = A \cap G / G \\
FScore = 2 P R / P + R
\end{split}
\end{equation}

Perhitungan pada rumus (2.1) dilakukan setelah anotator melakukan anotasi data yang diberikan dari hasil \textit{random sampling} data \textit{alignment} yang ada. \textit{Random sampling} dilakukan dengan cara megambil sebagian dari keseluruhan data secara acak.

Evaluasi yang dilakukan pada sistem WSD yang dibangun juga menggunakan nilai precision dan recall untuk menghitung F-Score. Pada perhitungan F-Score tersebut, teknik \textit{cross validation} juga digunakan untuk membagi data menjadi \textit{training} dan \textit{testing} data. Training data merupakan bagian dari data keseluruhan yang digunakan untuk memberikan \textit{knowledge} agar nanti mesin dapat melakukan klasifikasi terhadap \textit{input} yang diberikan. Sementara itu, \textit{testing} data merupakan bagian dari data yang akan diprediksi oleh mesin terlebih dahulu (dari hasil latihan dengan \textit{training} data), lalu diperiksa prediksinya dengan kelas sebenarnya pada \textit{testing} data. Metode \textit{cross validation} yang digunakan pada penelitian ini adalah K-Fold \textit{cross validation}. Ilustrasi dari metode tersebut dapat dilihat pada gambar \ref{fig:cross_val}.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{adit_pics/cross_validation}
	\caption{K-Fold \textit{cross validation} dengan nilai k=3}
	\label{fig:cross_val}
\end{figure}

Pada K-Fold \textit{cross validation}, variabel K akan digantikan dengan nilai yang menunjukan pembagian dari \textit{training} dan \textit{testing} yang akan dilakukan. Pada contoh gambar dengan k=3, keseluruhan data akan dibagi menjadi 3 bagian, lalu 1 bagian tersebut akan digunakan untuk \textit{testing} dan sisanya digunakan sebagai \textit{training}. Hal ini dilakukan sebanyak K kali, yang mana pada contoh gambar dilakukan sebanyak 3 kali. Hasil perhitungan F-Score nantinya akan diambil rata-ratanya dari setiap iterasi \textit{cross validation}.